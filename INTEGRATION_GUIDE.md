# Verba - GuÃ­a de IntegraciÃ³n Frontend-Backend

Esta guÃ­a explica cÃ³mo conectar el frontend de Verba (React) con el backend (FastAPI + WebSockets).

## ğŸ“‹ Tabla de Contenidos

1. [Arquitectura](#arquitectura)
2. [Prerequisitos](#prerequisitos)
3. [ConfiguraciÃ³n del Backend](#configuraciÃ³n-del-backend)
4. [ConfiguraciÃ³n del Frontend](#configuraciÃ³n-del-frontend)
5. [Desarrollo Local](#desarrollo-local)
6. [Flujo de ComunicaciÃ³n](#flujo-de-comunicaciÃ³n)
7. [Troubleshooting](#troubleshooting)

---

## ğŸ—ï¸ Arquitectura

### Stack TecnolÃ³gico

**Backend (`testing-mvp-sesame`)**
- FastAPI (servidor HTTP y WebSocket)
- Silero VAD (Voice Activity Detection)
- Faster Whisper (Speech-to-Text)
- Groq LLM (generaciÃ³n de respuestas)
- TTS (Text-to-Speech)
- Audio: PCM 16-bit, 16kHz

**Frontend (`UI-verba-mvp`)**
- React 19 + TypeScript
- Vite (dev server y build)
- Web Audio API (captura y reproducciÃ³n)
- WebSocket (comunicaciÃ³n bidireccional)
- Tailwind CSS

### Arquitectura de ComunicaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          WebSocket          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚
â”‚   Frontend      â”‚   Audio Streaming (PCM)      â”‚    Backend      â”‚
â”‚   (React)       â”‚                               â”‚   (FastAPI)     â”‚
â”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   Control Messages (JSON)    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                                  â”‚
        â”‚                                                  â”‚
        â–¼                                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web Audio API  â”‚                              â”‚  AI Pipeline    â”‚
â”‚  - Microphone   â”‚                              â”‚  - VAD          â”‚
â”‚  - Speakers     â”‚                              â”‚  - Whisper STT  â”‚
â”‚  - Processing   â”‚                              â”‚  - Groq LLM     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚  - TTS          â”‚
                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Prerequisitos

### Backend
- Python 3.8+
- PyAudio (requiere PortAudio instalado)
- CUDA (opcional, para GPU acceleration)

### Frontend
- Node.js 18+
- npm o yarn

### Navegador
- Chrome, Edge, o cualquier navegador moderno con soporte para:
  - Web Audio API
  - WebSocket
  - getUserMedia (acceso a micrÃ³fono)

---

## ğŸ”§ ConfiguraciÃ³n del Backend

### 1. Navegar al directorio del backend

```bash
cd ../testing-mvp-sesame/testing-mvp-sesame
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. Configurar variables de entorno

Crea un archivo `.env` en el directorio del backend:

```env
# Groq API Key (obtener en https://console.groq.com)
GROQ_API_KEY=your_api_key_here

# Opcional: ConfiguraciÃ³n de modelos
WHISPER_MODEL=base
TTS_VOICE=en-US-Neural2-C
```

### 4. Iniciar el servidor

```bash
python server.py
```

El backend estarÃ¡ disponible en:
- **HTTP**: `http://localhost:8000`
- **WebSocket**: `ws://localhost:8000/ws`

### 5. Verificar que funciona

Abre en tu navegador: `http://localhost:8000`

DeberÃ­as ver la interfaz bÃ¡sica del backend.

---

## ğŸ¨ ConfiguraciÃ³n del Frontend

### 1. Navegar al directorio del frontend

```bash
cd UI-verba-mvp
```

### 2. Instalar dependencias

```bash
npm install
```

### 3. Configurar variables de entorno

El archivo `.env` ya estÃ¡ creado con la configuraciÃ³n por defecto:

```env
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000
```

Para producciÃ³n, actualiza estos valores en `.env.production`:

```env
VITE_API_URL=https://api.tudominio.com
VITE_WS_URL=wss://api.tudominio.com
```

### 4. Iniciar el servidor de desarrollo

```bash
npm run dev
```

El frontend estarÃ¡ disponible en: `http://localhost:5173`

---

## ğŸš€ Desarrollo Local

### Levantar ambos servicios

**Terminal 1 - Backend:**
```bash
cd ../testing-mvp-sesame/testing-mvp-sesame
python server.py
```

**Terminal 2 - Frontend:**
```bash
cd UI-verba-mvp
npm run dev
```

### Flujo de trabajo

1. Abre el frontend en tu navegador: `http://localhost:5173`
2. Navega a la pÃ¡gina de conversaciÃ³n
3. Haz clic en "Empezar Clase"
4. Concede permisos de micrÃ³fono cuando el navegador lo solicite
5. Habla en inglÃ©s y recibe respuestas del agente

---

## ğŸ”„ Flujo de ComunicaciÃ³n

### Inicio de ConversaciÃ³n

```
1. Usuario presiona "Empezar Clase" en UI
   â†“
2. Frontend solicita permisos de micrÃ³fono
   â†“
3. Frontend establece conexiÃ³n WebSocket con backend
   â†“
4. Backend acepta conexiÃ³n y carga modelos
   â†“
5. Frontend comienza a capturar audio del micrÃ³fono
   â†“
6. Audio se convierte a PCM Int16 y se envÃ­a por WebSocket
```

### Procesamiento de Audio (Flujo Continuo)

```
Frontend (Capture)                  Backend (Processing)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MicrÃ³fono capture    â”€â”€â”€PCMâ”€â”€â–º      VAD Detection
                                    â”‚
                                    â”œâ”€â–º Speech detected?
                                    â”‚   Yes: Buffer frames
                                    â”‚   No: Ignore
                                    â”‚
                                    â”œâ”€â–º Silence after speech?
                                    â”‚   Yes: Process buffer
                                    â”‚
                                    â”œâ”€â–º Whisper STT
                                    â”‚   (transcribe audio)
                                    â”‚
                                    â”œâ”€â–º Groq LLM
                                    â”‚   (generate response)
                                    â”‚
                                    â””â”€â–º TTS
                                        (synthesize speech)
                                        â”‚
Speaker playback     â—„â”€â”€â”€PCMâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mensajes de Control (JSON)

El backend puede enviar mensajes de control:

```json
// Limpiar buffer (interrupciones)
{
  "type": "CLEAR_BUFFER"
}

// TranscripciÃ³n del usuario
{
  "type": "TRANSCRIPT",
  "text": "Hello, how are you?"
}

// Respuesta del AI
{
  "type": "AI_RESPONSE",
  "text": "I'm doing great! How can I help you practice English today?"
}

// Cambio de estado
{
  "type": "STATE_CHANGE",
  "state": "PROCESSING" | "SPEAKING" | "LISTENING"
}
```

---

## ğŸ› Troubleshooting

### El frontend no se conecta al backend

**SÃ­ntomas:**
- Error: "Connection error. Please check if the backend is running."
- Estado: "Error de conexiÃ³n"

**Soluciones:**

1. **Verifica que el backend estÃ© corriendo:**
   ```bash
   # En otra terminal
   curl http://localhost:8000
   ```

2. **Verifica CORS:**
   El backend debe tener configurado CORS para aceptar requests desde `localhost:5173`.
   Esto ya estÃ¡ configurado en `server.py`.

3. **Verifica las URLs en `.env`:**
   ```env
   VITE_API_URL=http://localhost:8000
   VITE_WS_URL=ws://localhost:8000
   ```

4. **Reinicia el servidor de desarrollo:**
   ```bash
   # Mata el proceso (Ctrl+C) y reinicia
   npm run dev
   ```

### No se captura audio del micrÃ³fono

**SÃ­ntomas:**
- No se detecta voz
- El backend no recibe datos

**Soluciones:**

1. **Verifica permisos del navegador:**
   - Abre DevTools â†’ Console
   - Busca errores relacionados con `getUserMedia`
   - Concede permisos de micrÃ³fono

2. **Verifica el micrÃ³fono en configuraciÃ³n del sistema:**
   - macOS: System Preferences â†’ Sound â†’ Input
   - Windows: Settings â†’ Sound â†’ Input
   - Habla en el micrÃ³fono y verifica que se mueva la barra de volumen

3. **Usa Chrome/Edge en lugar de Safari:**
   Safari tiene limitaciones con Web Audio API

### Audio reproducido tiene cortes o lag

**SÃ­ntomas:**
- Audio entrecortado
- Latencia alta

**Soluciones:**

1. **Verifica la conexiÃ³n de red:**
   - Si usas WiFi, intenta ethernet
   - Reduce distancia al router

2. **Cierra aplicaciones que usen mucho CPU:**
   - El procesamiento de audio requiere recursos

3. **Actualiza el backend:**
   - Usa GPU si estÃ¡ disponible
   - El backend usa `faster-whisper` que puede aprovechar CUDA

### El TTS no cambia de voz

**SÃ­ntomas:**
- Seleccionas una voz diferente pero sigue sonando igual

**Soluciones:**

1. **Verifica que el backend soporte mÃºltiples voces:**
   - El endpoint `/api/set_voice` debe estar implementado
   - Verifica logs del backend al cambiar voz

2. **Reinicia la conversaciÃ³n:**
   - Para "Terminar Clase" y vuelve a empezar

---

## ğŸ“ Estructura de Archivos

### Frontend

```
UI-verba-mvp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useVoiceConversation.ts   # Hook principal de conversaciÃ³n
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ api.ts                     # Cliente API
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ audioHelpers.ts            # Procesamiento de audio
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ ConversationPageNew.tsx    # PÃ¡gina de conversaciÃ³n integrada
â”‚   â”‚   â””â”€â”€ TasksPage.tsx              # PÃ¡gina de tareas
â”‚   â””â”€â”€ App.tsx
â”œâ”€â”€ .env                                # Variables de entorno (no commit)
â”œâ”€â”€ .env.example                        # Template de variables
â””â”€â”€ INTEGRATION_GUIDE.md               # Esta guÃ­a
```

### Backend

```
testing-mvp-sesame/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ vad.py           # Voice Activity Detection
â”‚   â”‚   â”œâ”€â”€ asr.py           # Speech-to-Text
â”‚   â”‚   â”œâ”€â”€ llm.py           # Language Model
â”‚   â”‚   â”œâ”€â”€ tts.py           # Text-to-Speech
â”‚   â”‚   â””â”€â”€ orchestrator.py  # Orquestador principal
â”‚   â””â”€â”€ audio/
â”‚       â””â”€â”€ websocket_audio_manager.py  # Manejo de audio por WebSocket
â”œâ”€â”€ server.py                # Servidor FastAPI
â””â”€â”€ requirements.txt
```

---

## ğŸ¯ PrÃ³ximos Pasos

- [ ] Implementar feedback en tiempo real (pronunciaciÃ³n, fluidez, vocabulario)
- [ ] Agregar autenticaciÃ³n de usuarios
- [ ] Implementar historial de conversaciones
- [ ] Agregar mÃ¡s voces TTS
- [ ] Optimizar latencia con streaming bidireccional
- [ ] Deploy en producciÃ³n

---

## ğŸ“ Soporte

Si tienes problemas, revisa:
1. Esta guÃ­a de troubleshooting
2. Los logs del backend (`python server.py`)
3. La consola del navegador (DevTools â†’ Console)
4. Los logs de red (DevTools â†’ Network)

Para reportar bugs, crea un issue en el repositorio.
